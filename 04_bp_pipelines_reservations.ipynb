{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12818355",
   "metadata": {},
   "source": [
    "# Batch Prediction Pipeline Workaround for Reservations\n",
    "\n",
    "Reference docs: https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-2.20.0/ \n",
    "\n",
    "\n",
    "This is a sample, some parameters may differ base on your implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3324cd9b",
   "metadata": {},
   "source": [
    "## Create custom component that deploys a model to with a GPU reservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bb5622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.dsl import (\n",
    "    Input,\n",
    "    Output,\n",
    ")  # Common artifact types\n",
    "from google_cloud_pipeline_components.types.artifact_types import (\n",
    "    VertexEndpoint,\n",
    "    VertexModel,\n",
    ")\n",
    "\n",
    "\n",
    "@dsl.component(\n",
    "    base_image=\"python:3.11\",\n",
    "    packages_to_install=[\"google-cloud-aiplatform\", \"google-cloud-pipeline-components\"],\n",
    ")\n",
    "def create_endpoint_with_reservation(\n",
    "    endpoint: Input[VertexEndpoint],\n",
    "    model: str,\n",
    "    deployed_name: str,\n",
    "    machine_type: str,\n",
    "    accelerator_type: str,\n",
    "    accelerator_count: int,\n",
    "    reservation_zone: str,\n",
    "    project_id: str,\n",
    "    reservation_name: str,\n",
    "    min_replica: int,\n",
    "    max_replica: int,\n",
    "    location: str,\n",
    "    deployed_endpoint: Output[VertexEndpoint],\n",
    "    deployed_model: Output[VertexModel],\n",
    "    endpoint_id: Output[str],\n",
    ") -> None:\n",
    "    from google_cloud_pipeline_components.types.artifact_types import (\n",
    "        VertexModel,\n",
    "    )\n",
    "    from google.cloud import aiplatform\n",
    "\n",
    "    aiplatform.init(\n",
    "        project=project_id,\n",
    "        location=location,\n",
    "    )\n",
    "\n",
    "    endpoint_fqn = endpoint.uri.split(\"v1/\")[1]\n",
    "    model_fqn = f\"projects/{project_id}/locations/{location}/models/{model}\"\n",
    "    vertex_endpoint = aiplatform.Endpoint(endpoint_fqn)\n",
    "    vertex_model = aiplatform.Model(model_name=model_fqn)\n",
    "\n",
    "    vertex_endpoint.deploy(\n",
    "        model=vertex_model,\n",
    "        deployed_model_display_name=deployed_name,\n",
    "        machine_type=machine_type,\n",
    "        accelerator_type=accelerator_type,\n",
    "        accelerator_count=accelerator_count,\n",
    "        reservation_affinity_type=\"SPECIFIC_RESERVATION\",\n",
    "        reservation_affinity_key=\"compute.googleapis.com/reservation-name\",\n",
    "        reservation_affinity_values=[\n",
    "            f\"projects/{project_id}/zones/{reservation_zone}/reservations/{reservation_name}\"\n",
    "        ],\n",
    "        min_replica_count=min_replica,\n",
    "        max_replica_count=max_replica,\n",
    "        sync=True,\n",
    "    )\n",
    "    # return types\n",
    "    deployed_endpoint.uri = endpoint.uri\n",
    "    deployed_model.uri = f\"https://{location}-aiplatform.googleapis.com/v1/{model_fqn}\"\n",
    "    endpoint_id = endpoint.uri.split('/')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614eb0f4",
   "metadata": {},
   "source": [
    "## Build another custom component that does the batch prediction from a gcs location\n",
    "Note this is has some specific data manipulation to this model and may be different for other implementations\n",
    "\n",
    "```bash\n",
    "curl -L -o ~/Downloads/cifar10-python-in-csv.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/fedesoriano/cifar10-python-in-csv\n",
    "```\n",
    "\n",
    "Unzip the file then upload the test file to the bucket.\n",
    "\n",
    "```bash\n",
    "gsutil cp test.csv gs://model_experimentation_2025/prediction_data/test.csv\n",
    "```\n",
    "\n",
    "#### Next, upload the Spark batch predict script that leverages the custom endpoint to storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab929164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://spark_batch_predict.py [Content-Type=text/x-python]...\n",
      "/ [1 files][  2.8 KiB/  2.8 KiB]                                                \n",
      "Operation completed over 1 objects/2.8 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "script_location = 'gs://model_experimentation_2025/scripts/spark_batch_predict.py'\n",
    "! gsutil cp spark_batch_predict.py $script_location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b1dd3e",
   "metadata": {},
   "source": [
    "## Important - make sure you enable `roles/compute.viewer` permissions for your Vertex Service Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57daab8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated IAM policy for reservation [a100-custom-image-reservation].\n",
      "bindings:\n",
      "- members:\n",
      "  - serviceAccount:vertex-sa@wortz-project-352116.iam.gserviceaccount.com\n",
      "  role: roles/compute.admin\n",
      "- members:\n",
      "  - serviceAccount:vertex-sa@wortz-project-352116.iam.gserviceaccount.com\n",
      "  role: roles/compute.futureReservationAdmin\n",
      "- members:\n",
      "  - serviceAccount:vertex-sa@wortz-project-352116.iam.gserviceaccount.com\n",
      "  role: roles/compute.instanceAdmin\n",
      "- members:\n",
      "  - serviceAccount:679926387543-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:service-679926387543@gcp-sa-aiplatform.iam.gserviceaccount.com\n",
      "  - serviceAccount:vertex-sa@wortz-project-352116.iam.gserviceaccount.com\n",
      "  role: roles/compute.viewer\n",
      "etag: BwY2nZYQIBE=\n",
      "version: 1\n"
     ]
    }
   ],
   "source": [
    "#### Bind SA to the reservation\n",
    "PROJECT_NUMBER = 679926387543\n",
    "\n",
    "! gcloud compute reservations add-iam-policy-binding \\\n",
    "    a100-custom-image-reservation \\\n",
    "    --zone=us-central1-b \\\n",
    "    --member=\"serviceAccount:service-$PROJECT_NUMBER@gcp-sa-aiplatform.iam.gserviceaccount.com\" \\\n",
    "    --role=\"roles/compute.viewer\" \\\n",
    "    --project=wortz-project-352116"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c45b22",
   "metadata": {},
   "source": [
    "## Pipeline with standard components integrated into the custom reservation deploy and batch predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bca9209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp import dsl\n",
    "from google_cloud_pipeline_components.v1.endpoint import (\n",
    "    EndpointCreateOp,\n",
    "    EndpointDeleteOp,\n",
    "    ModelUndeployOp,\n",
    ")\n",
    "from google_cloud_pipeline_components.v1.dataproc import DataprocPySparkBatchOp\n",
    "\n",
    "bucket = (\"model_experimentation_2025\",)\n",
    "\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"deploy-model-with-reserved-gpu\",\n",
    "    description=\"Deploys a model to an endpoint using a reserved GPU.\",\n",
    ")\n",
    "def deploy_model_pipeline(\n",
    "    project_id: str,\n",
    "    model: str,\n",
    "    region: str,\n",
    "    shared_project_id: str,\n",
    "    zone: str,\n",
    "    reservation_name: str,\n",
    "    endpoint_display_name: str,\n",
    "    deployed_model_display_name: str,\n",
    "    machine_type: str,\n",
    "    accelerator_type: str,\n",
    "    bucket: str,\n",
    "    prediction_input_blob: str,\n",
    "    prediction_output_blob: str,\n",
    "):\n",
    "\n",
    "    # 1. Create an endpoint\n",
    "    create_endpoint_task = EndpointCreateOp(\n",
    "        project=project_id,\n",
    "        location=region,\n",
    "        display_name=endpoint_display_name,\n",
    "    )\n",
    "\n",
    "    # 2. Deploy the model to the endpoint with reserved GPU\n",
    "    model_deploy_op = create_endpoint_with_reservation(\n",
    "        endpoint=create_endpoint_task.outputs[\"endpoint\"],\n",
    "        model=model,\n",
    "        location=region,\n",
    "        deployed_name=deployed_model_display_name,\n",
    "        machine_type=machine_type,\n",
    "        accelerator_type=accelerator_type,\n",
    "        accelerator_count=1,\n",
    "        reservation_zone=zone,\n",
    "        project_id=shared_project_id,\n",
    "        reservation_name=reservation_name,\n",
    "        min_replica=1,\n",
    "        max_replica=2,\n",
    "    )\n",
    "    # 3. Dataproc spark-based batch prediction job here\n",
    "    batch_predict_op = DataprocPySparkBatchOp(\n",
    "        main_python_file_uri=\"gs://model_experimentation_2025/scripts/spark_batch_predict.py\",\n",
    "        args=[\n",
    "            project_id,\n",
    "            region,\n",
    "            model_deploy_op.outputs[\"endpoint_id\"],\n",
    "            bucket,\n",
    "            prediction_input_blob,\n",
    "            prediction_output_blob,\n",
    "            30,\n",
    "        ],\n",
    "    )\n",
    "    # 4. Teardown of resources post-prediction\n",
    "    model_undeploy_op = ModelUndeployOp(\n",
    "        endpoint=model_deploy_op.outputs[\"deployed_endpoint\"],\n",
    "        model=model_deploy_op.outputs[\"deployed_model\"],\n",
    "        # traffic_split={\"0\": 100} # Optional: to ensure all traffic is removed from this model_id\n",
    "        # If this is the only model, it will be removed.\n",
    "    ).after(batch_predict_op)\n",
    "\n",
    "    delete_endpoint_op = EndpointDeleteOp(\n",
    "        endpoint=model_deploy_op.outputs[\n",
    "            \"deployed_endpoint\"\n",
    "        ],  # Use the same endpoint from deploy op\n",
    "    )\n",
    "    delete_endpoint_op.after(batch_predict_op)  # Explicitly set dependency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5482b06f",
   "metadata": {},
   "source": [
    "## Compile the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f332a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func=deploy_model_pipeline,\n",
    "    package_path=\"predict_w_reservations.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9df8a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your project ID, region, etc.\n",
    "import time\n",
    "\n",
    "epoch_time = time.time()\n",
    "pipeline_params = dict(\n",
    "    project_id=\"wortz-project-352116\",\n",
    "    model=\"3416616934593003520\",\n",
    "    region=\"us-central1\",\n",
    "    shared_project_id=\"wortz-project-352116\",\n",
    "    zone=\"us-central1-b\",\n",
    "    reservation_name=\"a100-custom-image-reservation\",\n",
    "    endpoint_display_name=\"Reservation_Endpoint\",\n",
    "    deployed_model_display_name=\"My_deployed_model\",\n",
    "    accelerator_type=\"NVIDIA_TESLA_A100\",\n",
    "    machine_type=\"a2-highgpu-1g\",\n",
    "    bucket=\"model_experimentation_2025\",\n",
    "    prediction_input_blob=\"prediction_data/test.csv\",\n",
    "    prediction_output_blob=f\"output_data/predictions_{epoch_time}.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e6654d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/679926387543/locations/us-central1/pipelineJobs/deploy-model-with-reserved-gpu-20250603185647\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/679926387543/locations/us-central1/pipelineJobs/deploy-model-with-reserved-gpu-20250603185647')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/deploy-model-with-reserved-gpu-20250603185647?project=679926387543\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(\n",
    "    project=pipeline_params[\"project_id\"],\n",
    "    location=pipeline_params[\"region\"],\n",
    "    service_account=\"vertex-sa@wortz-project-352116.iam.gserviceaccount.com\",\n",
    ")\n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name=f\"Predictions with GPU Reservations\",\n",
    "    template_path=\"predict_w_reservations.json\",\n",
    "    parameter_values=pipeline_params,\n",
    "    project=pipeline_params[\"project_id\"],\n",
    "    location=pipeline_params[\"region\"],\n",
    "    enable_caching=True,\n",
    ")\n",
    "\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7249b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a9c005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# one_sample = datasets[\"test\"].map(scale).take(1)\n",
    "# list_data = list(one_sample.as_numpy_iterator())\n",
    "# instances = {\"instances\": list_data[0][0].tolist()}\n",
    "# json_str = json.dumps(instances)\n",
    "# with open(\"data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(json_str, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
